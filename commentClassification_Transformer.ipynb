{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:9032/notebooks/Session_5_TorchText_practice/Untitled2.ipynb is exactly the same code with ofcourse the definition of encoer different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://www.manythings.org/anki/deu-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip deu-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in this cod we are reading teh data from the csv file ..this is important as most of the custom dataset will be in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy.data import Field,TabularDataset,BucketIterator  \n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('deu.txt', sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeURLs(text):\n",
    "    URLless_string=text\n",
    "    print(text)\n",
    "    try:\n",
    "        \n",
    "        URLless_string = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
    "        print(\"removed url\")\n",
    "    except:\n",
    "        print(\"some error\")\n",
    "    return URLless_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df.columns=['English','German','Notes']\n",
    "# # subDf=df[['English','German']]\n",
    "\n",
    "# # subDf.to_csv(\"deu.csv\")\n",
    "# df = pd.read_csv('data/comments_all.csv')\n",
    "# df=df[['commentText','commentClassification']]\n",
    "# df=df[df['commentClassification'].isin(['LOGISTICS_SUGGESTION','BUGGYCODE_SUGGESTION','COMPLETENESS_SUGGESTION','REFACTORING_SUGGESTION','CODE_SUGGESTION'])]\n",
    "# df['commentText']=df['commentText'].apply(lambda x:removeURLs(x))\n",
    "# df['commentClassification']=\"add \"+df['commentClassification']+\" end\"\n",
    "# df.to_csv(\"data/comments_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[191]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/comments_test.csv')\n",
    "# df\n",
    "# df=df[['commentText','commentClassification']]\n",
    "# df['commentText']=df['commentText'].apply(lambda x:removeURLs(x))\n",
    "# df['commentClassification']=\"add \"+df['commentClassification']+\" end\"\n",
    "# #df.to_csv(\"data/comments_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields={'commentText':('SRC',SRC),'commentClassification':('TRG',TRG)}\n",
    "\n",
    "train_data,test_data=TabularDataset.splits(\n",
    "                                    path='data',\n",
    "                                    train='attentionTrain.csv',#this is the traing file\n",
    "                                    test='attentionTest.csv',##this is the test file\n",
    "                                    format='csv',\n",
    "                                    fields=fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 1)\n",
    "TRG.build_vocab(train_data, min_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code', 'suggestion']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(test_data.examples[1])['TRG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<sos>',\n",
       " '<eos>',\n",
       " 'suggestion',\n",
       " 'refactoring',\n",
       " 'buggycode',\n",
       " 'code',\n",
       " 'questioning',\n",
       " 'completeness',\n",
       " 'logistics',\n",
       " 'spelling',\n",
       " 'logical',\n",
       " 'reuse',\n",
       " 'documentation']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    5,   41,   88,   35,   11,   20,   51,   44,  167,    4,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   14,  243,  362, 2197,  381,   47, 1077,   76,  801,    4,\n",
      "            3,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   22,   17,  546, 2428,    6,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   21,  162,  377,    4,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   49,   43,    4,  103,   99,    4,    3,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   22,  256, 1954,   13, 1061,    6,   11,   39,  784,   14,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,  278,   35,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,  109,  178,  462,  585,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   18,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   51,   44,  167,    4,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    8,   79,   30,  491,   27,   83,  399,    9,   30,  323,  287,\n",
      "            7,  255,   74,   24, 1894,    4,    3,    1,    1],\n",
      "        [   2,   22,   31,   11,   62,  277,   74,   24,  184, 1448,   31,  117,\n",
      "         2244,    4,    6,    3,    1,    1,    1,    1,    1],\n",
      "        [   2,   18,  625,  211, 1101, 1101,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   35,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   34,    9,   34,   35,   30,   51,   44,   80,    3,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   18,  160,  146,  159,  152,  156,   22,   11,   31,  237,    8,\n",
      "           84,   95,    6,    3,    1,    1,    1,    1,    1],\n",
      "        [   2,   10,    8,  174,  125,   69,   19,  656,    6,    3,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   38, 1253,  574,   19, 1457,  559,    4,    3,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   34,    9,  187,   20,   27,  328,   88,  187,    4,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   18,  655,  655,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   21,    8,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   22,   10,   96, 1063,  274,   29,    4,    6,    3,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   55,   31,    7,   95,   29,    6,    3,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   75,    7,  140,   13,   56,    7,  341,  137,   12,  250,    4,\n",
      "            3,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    7,   33,   10, 1664,   20,   11,  273,    7,   81,   19,  115,\n",
      "          307,   13,  220,    9,    6,    3,    1,    1,    1],\n",
      "        [   2,  229,   12,   14,    7,  352,  296,  108,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5, 1971,    7,   61,   57,  760,  232,  733,   28,   25,    4,\n",
      "            3,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   21,  263,  128,    4,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   30, 1735,  255,   27, 1703,   24,   11,  178,   57,  245,  255,\n",
      "            4,   28,  554,   17,  340,  298,    8,    4,    3],\n",
      "        [   2,    9,   39,   27, 1147,  113,   28,   25,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   14,  134,   82,    5,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   21,  284,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2,  9,  4,  3],\n",
      "        [ 2, 11,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2, 11,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2,  5,  4,  3]], device='cuda:0')\n",
      "i= 0\n",
      "[[2, 5, 41, 88, 35, 11, 20, 51, 44, 167, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 14, 243, 362, 2197, 381, 47, 1077, 76, 801, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1], [2, 22, 17, 546, 2428, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 21, 162, 377, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 49, 43, 4, 103, 99, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 22, 256, 1954, 13, 1061, 6, 11, 39, 784, 14, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 278, 35, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 109, 178, 462, 585, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 18, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 51, 44, 167, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 8, 79, 30, 491, 27, 83, 399, 9, 30, 323, 287, 7, 255, 74, 24, 1894, 4, 3, 1, 1], [2, 22, 31, 11, 62, 277, 74, 24, 184, 1448, 31, 117, 2244, 4, 6, 3, 1, 1, 1, 1, 1], [2, 18, 625, 211, 1101, 1101, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 35, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 34, 9, 34, 35, 30, 51, 44, 80, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 18, 160, 146, 159, 152, 156, 22, 11, 31, 237, 8, 84, 95, 6, 3, 1, 1, 1, 1, 1], [2, 10, 8, 174, 125, 69, 19, 656, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 38, 1253, 574, 19, 1457, 559, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 34, 9, 187, 20, 27, 328, 88, 187, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 18, 655, 655, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 21, 8, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 22, 10, 96, 1063, 274, 29, 4, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 55, 31, 7, 95, 29, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 75, 7, 140, 13, 56, 7, 341, 137, 12, 250, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1], [2, 7, 33, 10, 1664, 20, 11, 273, 7, 81, 19, 115, 307, 13, 220, 9, 6, 3, 1, 1, 1], [2, 229, 12, 14, 7, 352, 296, 108, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 1971, 7, 61, 57, 760, 232, 733, 28, 25, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1], [2, 21, 263, 128, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 30, 1735, 255, 27, 1703, 24, 11, 178, 57, 245, 255, 4, 28, 554, 17, 340, 298, 8, 4, 3], [2, 9, 39, 27, 1147, 113, 28, 25, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 14, 134, 82, 5, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 21, 284, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "update\n",
      "once\n",
      "verified\n",
      "we\n",
      "can\n",
      "merge\n",
      "after\n",
      "verification\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "use\n",
      "proper\n",
      "naming\n",
      "res\n",
      "doesn\n",
      "t\n",
      "imply\n",
      "any\n",
      "meaning\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "why\n",
      "not\n",
      "generic\n",
      "uploadresponse\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "remove\n",
      "log\n",
      "command\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "correct\n",
      "indentation\n",
      ".\n",
      "single\n",
      "tabs\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "why\n",
      "both\n",
      "mapperutils\n",
      "and\n",
      "gson\n",
      "?\n",
      "we\n",
      "should\n",
      "ideally\n",
      "use\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "qa\n",
      "verified\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "just\n",
      "return\n",
      "collections\n",
      ".singleton\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      " \n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "merge\n",
      "after\n",
      "verification\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "this\n",
      "condition\n",
      "will\n",
      "never\n",
      "be\n",
      "used\n",
      "since\n",
      "it\n",
      "will\n",
      "go\n",
      "inside\n",
      "the\n",
      "block\n",
      "only\n",
      "if\n",
      "isserialnumbersetting\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "why\n",
      "are\n",
      "we\n",
      "using\n",
      "first\n",
      "only\n",
      "if\n",
      "multiple\n",
      "beatids\n",
      "are\n",
      "being\n",
      "searched\n",
      ".\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      " \n",
      "export\n",
      "const\n",
      "ledgers\n",
      "ledgers\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "verified\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "get\n",
      "it\n",
      "get\n",
      "verified\n",
      "will\n",
      "merge\n",
      "after\n",
      "that\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      " \n",
      "ffc\n",
      "ed\n",
      "dbf\n",
      "da\n",
      "ae\n",
      "why\n",
      "we\n",
      "are\n",
      "getting\n",
      "this\n",
      "file\n",
      "changes\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "is\n",
      "this\n",
      "method\n",
      "already\n",
      "there\n",
      "in\n",
      "parent\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "add\n",
      "today\n",
      "support\n",
      "in\n",
      "bind\n",
      "parameter\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "get\n",
      "it\n",
      "tested\n",
      "can\n",
      "be\n",
      "merged\n",
      "once\n",
      "tested\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      " \n",
      "paper\n",
      "paper\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "remove\n",
      "this\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "why\n",
      "is\n",
      "default\n",
      "gstinvoicetemplate\n",
      "changed\n",
      "here\n",
      ".\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "what\n",
      "are\n",
      "the\n",
      "changes\n",
      "here\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "resolve\n",
      "the\n",
      "conflicts\n",
      "and\n",
      "change\n",
      "the\n",
      "target\n",
      "branch\n",
      "to\n",
      "development\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "the\n",
      "code\n",
      "is\n",
      "duplicated\n",
      "can\n",
      "we\n",
      "write\n",
      "the\n",
      "function\n",
      "in\n",
      "one\n",
      "model\n",
      "and\n",
      "call\n",
      "it\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "better\n",
      "to\n",
      "use\n",
      "the\n",
      "custom\n",
      "widget\n",
      "constants\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "mege\n",
      "the\n",
      "query\n",
      "from\n",
      "drop\n",
      "column\n",
      "batch\n",
      "i\n",
      "d\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "remove\n",
      "invalid\n",
      "spaces\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "will\n",
      "finally\n",
      "block\n",
      "be\n",
      "executed\n",
      "if\n",
      "we\n",
      "return\n",
      "from\n",
      "try\n",
      "block\n",
      ".\n",
      "i\n",
      "m\n",
      "not\n",
      "sure\n",
      "about\n",
      "this\n",
      ".\n",
      "<eos>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "it\n",
      "should\n",
      "be\n",
      "orderids\n",
      "array\n",
      "i\n",
      "d\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "use\n",
      "constant\n",
      "variable\n",
      "please\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "remove\n",
      "comments\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "tensor([[   2,   48,   12,   54,   15,   66,   79,   16,  256,   28,   25,   13,\n",
      "          620,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,  622,   11,  477,  258,    4,    5, 1686,    7,   66,    3,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,    8, 2301,  308,  106,   15,  377,    4,   27, 1781,   12,    7,\n",
      "          112,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,  207,   16,    8,    6,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   18,    4,    4,    4,  204,   97, 1903,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,  348,    5,    4,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,    5,   34,    9,   35,   13,   41,   50,   11,   30,   51,   88,\n",
      "           35,    4,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,  245,   12, 1243,    7,   79,    9,   30,   27,  229,    4,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   61,    5,    4,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,    5,   72,   47,  161,   33,  107,   19,    7,   33,    4,   34,\n",
      "            9,   57,  107,  150,    4,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   21,   70,   33,   21,  124,  102,    3,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   49,   43,    4,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,    5,   34,    9,   35,   13,   41,   50,   16,   51,    4,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   21,    8,   56,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   53,   44,    5,   14,   53,   44,   13,   89,    3,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   24,   11,  676,  176,   28,   25,   77,  239,  176,    4,   24,\n",
      "          239,  155,   77,   14,  155,   28,   25,   19, 2052,    4,    3,    1,\n",
      "            1],\n",
      "        [   2,   22,   31,   37,  283,  282,   29,  192,    7,   66,  579,   10,\n",
      "          248,   19, 1783,    6,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2, 2107,   75,    7,  140,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,    5,  333,    7,   50,   19,  250,  137,    4,    3,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   14,   16,  856,   19,  200,   16,  229,  498,    3,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   53,   44,  221,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,  147,  300,  708, 2100,   39,   27,  633,   57,    7,  954,    4,\n",
      "            3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   82,  362,    4,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   21,   70,   67,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   36,   60,  758,   88,  295,   11,   48,    7,  909,    3,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   24,   11,   72,   47,   48,    8,   70,   33,    5,   21,    9,\n",
      "            4,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   61,   10,   52,    4,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   93,   24,  210,   20,   27, 1523,   13,  141,  369,   19,  115,\n",
      "          205,    6,    5,   46,    7,  809,   95,    4,    3,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   17,   52,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   18, 1793,   20,   27,  173,  126,   98,  251,   71,   23,  321,\n",
      "          251,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   20,   11,  337,    7, 1780,   54,  711,  147,   83,   63,   17,\n",
      "            4,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1],\n",
      "        [   2,   11,   48,   12,  347,    8,  280,   44,  283,   60,  127,  342,\n",
      "            4,   16,  135,  225,    9,  323,   32,    9,   10, 2432,   87,    4,\n",
      "            3]], device='cuda:0')\n",
      "tensor([[ 2,  7,  4,  3],\n",
      "        [ 2, 11,  4,  3],\n",
      "        [ 2, 12,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2, 12,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2, 12,  4,  3],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2, 12,  4,  3],\n",
      "        [ 2, 11,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2, 12,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2, 12,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  5,  4,  3]], device='cuda:0')\n",
      "i= 1\n",
      "[[2, 48, 12, 54, 15, 66, 79, 16, 256, 28, 25, 13, 620, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 622, 11, 477, 258, 4, 5, 1686, 7, 66, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 8, 2301, 308, 106, 15, 377, 4, 27, 1781, 12, 7, 112, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 207, 16, 8, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 18, 4, 4, 4, 204, 97, 1903, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 348, 5, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 34, 9, 35, 13, 41, 50, 11, 30, 51, 88, 35, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 245, 12, 1243, 7, 79, 9, 30, 27, 229, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 61, 5, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 72, 47, 161, 33, 107, 19, 7, 33, 4, 34, 9, 57, 107, 150, 4, 3, 1, 1, 1, 1, 1, 1, 1], [2, 21, 70, 33, 21, 124, 102, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 49, 43, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 34, 9, 35, 13, 41, 50, 16, 51, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 21, 8, 56, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 53, 44, 5, 14, 53, 44, 13, 89, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 24, 11, 676, 176, 28, 25, 77, 239, 176, 4, 24, 239, 155, 77, 14, 155, 28, 25, 19, 2052, 4, 3, 1, 1], [2, 22, 31, 37, 283, 282, 29, 192, 7, 66, 579, 10, 248, 19, 1783, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2107, 75, 7, 140, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 333, 7, 50, 19, 250, 137, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 14, 16, 856, 19, 200, 16, 229, 498, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 53, 44, 221, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 147, 300, 708, 2100, 39, 27, 633, 57, 7, 954, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 82, 362, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 21, 70, 67, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 36, 60, 758, 88, 295, 11, 48, 7, 909, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 24, 11, 72, 47, 48, 8, 70, 33, 5, 21, 9, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 61, 10, 52, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 93, 24, 210, 20, 27, 1523, 13, 141, 369, 19, 115, 205, 6, 5, 46, 7, 809, 95, 4, 3, 1, 1, 1, 1], [2, 17, 52, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 18, 1793, 20, 27, 173, 126, 98, 251, 71, 23, 321, 251, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 20, 11, 337, 7, 1780, 54, 711, 147, 83, 63, 17, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 11, 48, 12, 347, 8, 280, 44, 283, 60, 127, 342, 4, 16, 135, 225, 9, 323, 32, 9, 10, 2432, 87, 4, 3]]\n",
      "length of file 25\n",
      "<sos>\n",
      "need\n",
      "to\n",
      "have\n",
      "a\n",
      "same\n",
      "condition\n",
      "for\n",
      "both\n",
      "i\n",
      "d\n",
      "and\n",
      "erpid\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "everywhere\n",
      "we\n",
      "follow\n",
      "camelcase\n",
      ".\n",
      "please\n",
      "ensure\n",
      "the\n",
      "same\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "this\n",
      "sounds\n",
      "more\n",
      "like\n",
      "a\n",
      "command\n",
      ".\n",
      "be\n",
      "gentle\n",
      "to\n",
      "the\n",
      "user\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "ticket\n",
      "for\n",
      "this\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      " \n",
      ".\n",
      ".\n",
      ".\n",
      "new\n",
      "set\n",
      "joinedtables\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "cleanup\n",
      "please\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "please\n",
      "get\n",
      "it\n",
      "verified\n",
      "and\n",
      "update\n",
      "pr\n",
      "we\n",
      "will\n",
      "merge\n",
      "once\n",
      "verified\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "try\n",
      "to\n",
      "swap\n",
      "the\n",
      "condition\n",
      "it\n",
      "will\n",
      "be\n",
      "better\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "query\n",
      "please\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "please\n",
      "don\n",
      "t\n",
      "hard\n",
      "code\n",
      "strings\n",
      "in\n",
      "the\n",
      "code\n",
      ".\n",
      "get\n",
      "it\n",
      "from\n",
      "strings\n",
      ".xml\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "remove\n",
      "commented\n",
      "code\n",
      "remove\n",
      "unnecessary\n",
      "lines\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "correct\n",
      "indentation\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "please\n",
      "get\n",
      "it\n",
      "verified\n",
      "and\n",
      "update\n",
      "pr\n",
      "for\n",
      "merge\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "remove\n",
      "this\n",
      "change\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "space\n",
      "after\n",
      "please\n",
      "use\n",
      "space\n",
      "after\n",
      "and\n",
      "before\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "if\n",
      "we\n",
      "saving\n",
      "outlet\n",
      "i\n",
      "d\n",
      "then\n",
      "its\n",
      "outlet\n",
      ".\n",
      "if\n",
      "its\n",
      "warehouse\n",
      "then\n",
      "use\n",
      "warehouse\n",
      "i\n",
      "d\n",
      "in\n",
      "orgid\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "why\n",
      "are\n",
      "you\n",
      "checking\n",
      "again\n",
      "here\n",
      "when\n",
      "the\n",
      "same\n",
      "thing\n",
      "is\n",
      "checked\n",
      "in\n",
      "getactionfetcher\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "plesae\n",
      "resolve\n",
      "the\n",
      "conflicts\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "please\n",
      "raise\n",
      "the\n",
      "pr\n",
      "in\n",
      "development\n",
      "branch\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "use\n",
      "for\n",
      "statement\n",
      "in\n",
      "else\n",
      "for\n",
      "better\n",
      "readability\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "space\n",
      "after\n",
      "comma\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "index\n",
      "based\n",
      "vendor\n",
      "pickup\n",
      "should\n",
      "be\n",
      "hidden\n",
      "from\n",
      "the\n",
      "caller\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "variable\n",
      "naming\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "remove\n",
      "commented\n",
      "line\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "check\n",
      "with\n",
      "design\n",
      "once\n",
      "whether\n",
      "we\n",
      "need\n",
      "the\n",
      "accordion\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "if\n",
      "we\n",
      "don\n",
      "t\n",
      "need\n",
      "this\n",
      "commented\n",
      "code\n",
      "please\n",
      "remove\n",
      "it\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "query\n",
      "is\n",
      "required\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "these\n",
      "if\n",
      "conditions\n",
      "can\n",
      "be\n",
      "combined\n",
      "and\n",
      "put\n",
      "them\n",
      "in\n",
      "one\n",
      "right\n",
      "?\n",
      "please\n",
      "do\n",
      "the\n",
      "necessary\n",
      "changes\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "not\n",
      "required\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      " \n",
      "getter\n",
      "can\n",
      "be\n",
      "done\n",
      "at\n",
      "class\n",
      "level\n",
      "instead\n",
      "of\n",
      "field\n",
      "level\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "can\n",
      "we\n",
      "show\n",
      "the\n",
      "genericformdatanew\n",
      "have\n",
      "zero\n",
      "index\n",
      "used\n",
      "or\n",
      "not\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 25\n",
      "<sos>\n",
      "we\n",
      "need\n",
      "to\n",
      "clean\n",
      "this\n",
      "up\n",
      "after\n",
      "checking\n",
      "with\n",
      "other\n",
      "team\n",
      ".\n",
      "for\n",
      "now\n",
      "let\n",
      "it\n",
      "go\n",
      "as\n",
      "it\n",
      "is\n",
      "urgent\n",
      "fix\n",
      ".\n",
      "<eos>\n",
      "------\n",
      "tensor([[   2,   22,   10,    8,   52,    6,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   21,   70,  695,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   75,  140,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   79,   16,  878,   58,    6,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   21,   44,  377,    4,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   10,    9,   48,   16,  642,    6,    6,    6,    3,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   28,  431,   37,   54,  987,    7,  288,   59,   65,    4,    5,\n",
      "          404,    9,  589,   80,    3,    1,    1,    1,    1],\n",
      "        [   2,   20,   27,   19,  108,   84,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   18,   26,   15,   26,   40,   15,   42,   42,    9,   39,   27,\n",
      "          169,  895,   36,    3,    1,    1,    1,    1,    1],\n",
      "        [   2,   38,   49,  128, 1882,  276,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   75,    7,  140,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   22,   10,    8,  110,    6,   13,   31,   11,   62,    9,   19,\n",
      "           76,   23,  652,  566,    6,    3,    1,    1,    1],\n",
      "        [   2,   34,    7,   90,  387,   57,  107,  150,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   97,  341,   12,  250,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   21,  129,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   87,   43,    4,   14,   99,    4,    3,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   34,    8,   35,    4,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   24,    8,   82,  327, 1983,    5,  122,    4,    3,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   38,  445,  218,   36,   13,   65,   75,  140,    3,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   38,   36,   16,  441,   13,  570,  875,  505,    3,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   53,   89,   13,   44,    4,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   20,   11,  658,    9,   57,  195,    6,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   75,    7,  105,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   21,   70,   33,    3,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,  292,   61,   12,   36,    7,   14,   23,  147,  200,   11,\n",
      "           30,   54,   12,  855,    7,   63,   79,    4,    3],\n",
      "        [   2,   22,  110,  118,   36,    6,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,   14,  257,   16,  103,   67,   24,  210,   65,    4,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 2286,  441,  637,   10,  117,   83,    4,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   61,   10,   52,   29,   65,    4,    3,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,  122,    8,    6,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,  997,   65,   20,   11,  121,    8,   19,   15,  134,   84,    6,\n",
      "            3,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,    5,  104,   50,   16,  379,  137,    4,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2,  8,  3,  1],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2, 12,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2, 11,  4,  3],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2, 10,  4,  3],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2,  8,  3,  1],\n",
      "        [ 2,  5,  4,  3],\n",
      "        [ 2,  7,  4,  3],\n",
      "        [ 2,  9,  4,  3],\n",
      "        [ 2, 11,  4,  3],\n",
      "        [ 2,  6,  4,  3],\n",
      "        [ 2, 10,  4,  3]], device='cuda:0')\n",
      "i= 2\n",
      "[[2, 22, 10, 8, 52, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 21, 70, 695, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 75, 140, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 79, 16, 878, 58, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 21, 44, 377, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 10, 9, 48, 16, 642, 6, 6, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 28, 431, 37, 54, 987, 7, 288, 59, 65, 4, 5, 404, 9, 589, 80, 3, 1, 1, 1, 1], [2, 20, 27, 19, 108, 84, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 18, 26, 15, 26, 40, 15, 42, 42, 9, 39, 27, 169, 895, 36, 3, 1, 1, 1, 1, 1], [2, 38, 49, 128, 1882, 276, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 75, 7, 140, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 22, 10, 8, 110, 6, 13, 31, 11, 62, 9, 19, 76, 23, 652, 566, 6, 3, 1, 1, 1], [2, 34, 7, 90, 387, 57, 107, 150, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 97, 341, 12, 250, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 21, 129, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 87, 43, 4, 14, 99, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 34, 8, 35, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 24, 8, 82, 327, 1983, 5, 122, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 38, 445, 218, 36, 13, 65, 75, 140, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 38, 36, 16, 441, 13, 570, 875, 505, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 53, 89, 13, 44, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 20, 11, 658, 9, 57, 195, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 75, 7, 105, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 21, 70, 33, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 292, 61, 12, 36, 7, 14, 23, 147, 200, 11, 30, 54, 12, 855, 7, 63, 79, 4, 3], [2, 22, 110, 118, 36, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 14, 257, 16, 103, 67, 24, 210, 65, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2286, 441, 637, 10, 117, 83, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 61, 10, 52, 29, 65, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 122, 8, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 997, 65, 20, 11, 121, 8, 19, 15, 134, 84, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1], [2, 5, 104, 50, 16, 379, 137, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "length of file 21\n",
      "<sos>\n",
      "why\n",
      "is\n",
      "this\n",
      "required\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "remove\n",
      "commented\n",
      "styling\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "resolve\n",
      "conflicts\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "condition\n",
      "for\n",
      "warehouseid\n",
      "!\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "remove\n",
      "after\n",
      "command\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "is\n",
      "it\n",
      "need\n",
      "for\n",
      "logging\n",
      "?\n",
      "?\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "i\n",
      "hope\n",
      "you\n",
      "have\n",
      "considered\n",
      "the\n",
      "map\n",
      "data\n",
      "also\n",
      ".\n",
      "please\n",
      "verify\n",
      "it\n",
      "against\n",
      "that\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "can\n",
      "be\n",
      "in\n",
      "constants\n",
      "file\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      " \n",
      "c\n",
      "a\n",
      "c\n",
      "b\n",
      "a\n",
      "e\n",
      "e\n",
      "it\n",
      "should\n",
      "be\n",
      "product\n",
      ".please\n",
      "check\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "add\n",
      "correct\n",
      "spaces\n",
      "isapi\n",
      "false\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "resolve\n",
      "the\n",
      "conflicts\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "why\n",
      "is\n",
      "this\n",
      "removed\n",
      "?\n",
      "and\n",
      "are\n",
      "we\n",
      "using\n",
      "it\n",
      "in\n",
      "any\n",
      "of\n",
      "our\n",
      "reports\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "get\n",
      "the\n",
      "string\n",
      "literal\n",
      "from\n",
      "strings\n",
      ".xml\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "set\n",
      "target\n",
      "to\n",
      "development\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "remove\n",
      "comment\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "fix\n",
      "indentation\n",
      ".\n",
      "use\n",
      "tabs\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "get\n",
      "this\n",
      "verified\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "if\n",
      "this\n",
      "variable\n",
      "means\n",
      "modifiedoldlayouts\n",
      "please\n",
      "rename\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "add\n",
      "server\n",
      "version\n",
      "check\n",
      "and\n",
      "also\n",
      "resolve\n",
      "conflicts\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "add\n",
      "check\n",
      "for\n",
      "primary\n",
      "and\n",
      "secondary\n",
      "van\n",
      "sale\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "space\n",
      "before\n",
      "and\n",
      "after\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "can\n",
      "we\n",
      "pick\n",
      "it\n",
      "from\n",
      "theme\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "resolve\n",
      "the\n",
      "conflict\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "remove\n",
      "commented\n",
      "code\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "share\n",
      "query\n",
      "to\n",
      "check\n",
      "the\n",
      "use\n",
      "of\n",
      "index\n",
      "else\n",
      "we\n",
      "will\n",
      "have\n",
      "to\n",
      "split\n",
      "the\n",
      "or\n",
      "condition\n",
      ".\n",
      "<eos>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "why\n",
      "removed\n",
      "null\n",
      "check\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "use\n",
      "brackets\n",
      "for\n",
      "single\n",
      "line\n",
      "if\n",
      "conditions\n",
      "also\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "skucodeindex\n",
      "primary\n",
      "indexes\n",
      "is\n",
      "being\n",
      "used\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "query\n",
      "is\n",
      "required\n",
      "here\n",
      "also\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "rename\n",
      "this\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "currencysign\n",
      "also\n",
      "can\n",
      "we\n",
      "keep\n",
      "this\n",
      "in\n",
      "a\n",
      "constant\n",
      "file\n",
      "?\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n",
      "length of file 21\n",
      "<sos>\n",
      "please\n",
      "create\n",
      "pr\n",
      "for\n",
      "dev\n",
      "branch\n",
      ".\n",
      "<eos>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_iterator):\n",
    "    print(batch.SRC)\n",
    "    print(batch.TRG)\n",
    "    print(\"i=\",i)\n",
    "    lst=batch.SRC.tolist()\n",
    "    print(lst)\n",
    "    for b in lst:\n",
    "        print(\"length of file\", len(b))\n",
    "        for j in b:\n",
    "            print(SRC.vocab.itos[j])\n",
    "        print(\"------\")\n",
    "    #print(vars(train_data.examples[i])['TRG'])\n",
    "    if(i==2):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['check',\n",
       " 'for',\n",
       " 'null',\n",
       " 'domain',\n",
       " 'url',\n",
       " 'add',\n",
       " 'log',\n",
       " 'also',\n",
       " 'if',\n",
       " 'url',\n",
       " 'is',\n",
       " 'null']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data.examples[1])['SRC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now we will start building the encoder class\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,#length of the vocabulary\n",
    "                 hid_dim,#512\n",
    "                 n_layers,#6\n",
    "                 n_heads,#8\n",
    "                 pf_dim,#output dimention\n",
    "                 dropout,\n",
    "                 device,#cuda\n",
    "                 max_length=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device=device\n",
    "        \n",
    "        #input embedding\n",
    "        self.tok_embedding=nn.Embedding(input_dim,hid_dim)\n",
    "        ## convert the indices of the words to the position embedding. since there can be just \n",
    "        ## 100 tokens in the sentence hence the embedding will be a matrix of 100*hid_dim\n",
    "        self.pos_embedding=nn.Embedding(max_length,hid_dim) \n",
    "        \n",
    "        ##create layers ..what happens in each layer is listed\n",
    "        self.layers=nn.ModuleList([EncoderLayer(hid_dim, ## this is 512\n",
    "                                                n_heads, ## MHA has n_heads\n",
    "                                                pf_dim, ## the dimentions of output\n",
    "                                                dropout,\n",
    "                                                device\n",
    "                                                )for _ in range(n_layers)])\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##define dropout\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.scale=torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    \n",
    "    ##src=it is a set of input values that are in the form of batch\n",
    "    ##after the Encoder running will get the inputs for the decoder\n",
    "    def forward(self,src,src_mask):\n",
    "        batch_size=src.shape[0]\n",
    "        src_len=src.shape[1]\n",
    "        \n",
    "        ##it will fill the pos vector with the src_len numbers which are repeated batch_size\n",
    "        ## also for the combination to happen between the pos vector and the input they \n",
    "        ## must be of the same dimention\n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        \n",
    "        ##this is how the batch will look like after combining the scaling factor, positional embedding\n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        \n",
    "        ##pass it to all the layers...these layers is the MHA & feedforward network + residual connections\n",
    "        ##after the operations also the same variable src is being updated\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "            \n",
    "        return src\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim,  \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the two norm layers\n",
    "        self.self_attn_layer_norm=nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm=nn.LayerNorm(hid_dim)\n",
    "        \n",
    "        ## MultiHeadAttentionLayer is a class that we will call\n",
    "        self.self_attention=MultiHeadAttentionLayer(hid_dim,n_heads,dropout,device)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        ## the feedforward\n",
    "        ## PositionwiseFeedforwardLayer is a class that will be called\n",
    "        self.positionwise_feedforward=PositionwiseFeedforwardLayer(hid_dim,pf_dim,dropout)\n",
    "        \n",
    "    ##src is the batch wise data\n",
    "    def forward(self,src,src_mask):\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]...basically each token will be of hid_dim\n",
    "        ##[[.1,.1,.2,.3,.4,.4,...512 entries]\n",
    "        ##[.1,.1,.2,.3,.4,.4,...512 entries]] two tokens whose embedding is 512 length and are in the form of a batch\n",
    "        \n",
    "        \n",
    "        #self_attention...it will take the query,key,value matrix and then calculate the self attention. Also to use\n",
    "        ## the same code for the decoder by passing a src_mask\n",
    "        #_src,_=self.self_attention(query=src,key=src,value=src,mask=src_mask)\n",
    "        \n",
    "        _src,_=self.self_attention(src,src,src,src_mask)\n",
    "        \n",
    "        ##apply the dropout, residual and pass to norm\n",
    "        src=self.self_attn_layer_norm(src+self.dropout(_src))\n",
    "        \n",
    "        \n",
    "        _src=self.positionwise_feedforward(src)\n",
    "        \n",
    "        src=self.ff_layer_norm(src+self.dropout(_src))\n",
    "        \n",
    "        return src\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "    \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim=hid_dim\n",
    "        self.n_heads=n_heads\n",
    "        self.head_dim=hid_dim // n_heads\n",
    "        \n",
    "        ##this is as good as definng a Wq...when ever we will have a linear layer there will be a W associated\n",
    "        ## also instead of decalring it for the head_dim we are declaring it for the hidden dimention and then \n",
    "        ## we will divide the matrix into the n_heads.. this way the code is much general\n",
    "        self.fc_q=nn.Linear(hid_dim,hid_dim)\n",
    "        self.fc_k=nn.Linear(hid_dim,hid_dim)\n",
    "        self.fc_v=nn.Linear(hid_dim,hid_dim)\n",
    "        \n",
    "        ## this is the last weight matrix that will be used at the time of concatenation of the outputs        \n",
    "        self.fc_o=nn.Linear(hid_dim,hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        ##the scaling factor as in scale dot products...this will be the sqrt of the dimention that we are using\n",
    "        self.scale=torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "    \n",
    "    \n",
    "    ## there are lot of transformation happeing\n",
    "    ## [batch,word,hid_dim] -> [batch,word,n_head,head_dim] (view)-> [batch,n_head,word,head_dim] (permute)\n",
    "    ## ->[batch,words,number_heads,head_dim] (permute +contiguous) -> [batch,words,hid_dim] (view)\n",
    "    ##\n",
    "    ##\n",
    "    def forward(self,query,key,value,mask=None):\n",
    "        \n",
    "        #assuming that the matrices have an additional batch dimention\n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        #Q=[batch,word,hid_dim]\n",
    "        Q=self.fc_q(query)\n",
    "        K=self.fc_k(key)\n",
    "        V=self.fc_v(value)\n",
    "        \n",
    "        #Q is of the dimention [batch,word,hid_dim]\n",
    "        # we want to create new Q which is [batch,num_head,words,head_dim]\n",
    "        # it is a 2 step thing...\n",
    "        # step1 [batch,word,hid_dim] -> [batch,word,n_head,head_dim] using views\n",
    "        #step2 using permute change the axis from [batch,word,n_head,head_dim] -> [batch,n_head,word,head_dim]\n",
    "        Q=Q.view(batch_size,-1,self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "        K=K.view(batch_size,-1,self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "        V=V.view(batch_size,-1,self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "        \n",
    "        \n",
    "        ## now compuet the energy ..we need to take a transpose of K\n",
    "        ## this will give us energy dimentions as [batch_len,number_heads,number_words,number_words]\n",
    "        energy=torch.matmul(Q,K.permute(0,1,3,2))/self.scale\n",
    "        #0, 1, 3, 2\n",
    "        ## this is how we will use the mask\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        #attentiox=[batch,number_heads,words,words]\n",
    "        attention=torch.softmax(energy,dim=-1)\n",
    "        \n",
    "        ##this will give x=[batch,number_heads,words,head_dim]\n",
    "        x=torch.matmul(self.dropout(attention),V)\n",
    "        \n",
    "        #batchnumber,words,heads,head_dim..this is some memory optimization operation\n",
    "        # but the x is also changed from [batch,number_heads,words,head_dim] -> [batch,words,number_heads,head_dim]\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        #now number_heads and head_dim are getting combined together to get the single continuous tensor\n",
    "        #[batch,words,number_heads,head_dim] -> [batch,words,hid_dim]\n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        \n",
    "        \n",
    "        ##pass it through the linear layer\n",
    "        x=self.fc_o(x)\n",
    "        \n",
    "        \n",
    "        #x=x = [batch size, words, hid dim]\n",
    "        return x,attention\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##positionwise feed forward layer\n",
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #x = [batch size, seq len, hid_dim]->[batch size, seq len, pf_dim]    \n",
    "        x=self.dropout(torch.relu(self.fc_1(x)))\n",
    "        \n",
    "        #x=[batch size, seq len, pf_dim]->[batch size, seq len, hid_dim]\n",
    "        x=self.fc_2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##decoder\n",
    "##this should be simialr to the encoder class so I am strating by copying the encoder class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim,#length of the vocabulary\n",
    "                 hid_dim,#512\n",
    "                 n_layers,#6\n",
    "                 n_heads,#8\n",
    "                 pf_dim,#output dimention\n",
    "                 dropout,\n",
    "                 device,#cuda\n",
    "                 max_length=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device=device\n",
    "        \n",
    "        #input embedding\n",
    "        self.tok_embedding=nn.Embedding(output_dim,hid_dim)\n",
    "        ## convert the indices of the words to the position embedding. since there can be just \n",
    "        ## 100 tokens in the sentence hence the embedding will be a matrix of 100*hid_dim\n",
    "        self.pos_embedding=nn.Embedding(max_length,hid_dim) \n",
    "        \n",
    "        ##create layers ..what happens in each layer is listed\n",
    "        self.layers=nn.ModuleList([DecoderLayer(hid_dim, ## this is 512\n",
    "                                                n_heads, ## MHA has n_heads\n",
    "                                                pf_dim, ## the dimentions of output\n",
    "                                                dropout,\n",
    "                                                device\n",
    "                                                )\n",
    "                                    for _ in range(n_layers)])\n",
    "        \n",
    "        \n",
    "        ##thiis is extra\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        ##define dropout\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.scale=torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    \n",
    "    ## the forward function will be little different than the Encoder\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        batch_size=trg.shape[0]\n",
    "        trg_len=trg.shape[1]\n",
    "        \n",
    "        ##it will fill the pos vector with the src_len numbers which are repeated batch_size\n",
    "        ## also for the combination to happen between the pos vector and the input they \n",
    "        ## must be of the same dimention\n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        \n",
    "        ##this is how the batch will look like after combining the scaling factor, positional embedding\n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        \n",
    "        ##pass it to all the layers...these layers is the MHA & feedforward network + residual connections\n",
    "        ##after the operations also the same variable src is being updated\n",
    "        for layer in self.layers:\n",
    "            trg,attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "            \n",
    "        output=self.fc_out(trg)\n",
    "        return output,attention\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        #norm for the self attention\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        \n",
    "        #norm for the encoder _attentions\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        \n",
    "        #the feedfoward layer normalization..this one is after the encoder-attentions\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        \n",
    "        ## calculate the self attentions\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        \n",
    "        # calculate the attention using the K,V coming from encoder\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        \n",
    "        #feedforward\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,trg,enc_src,trg_mask,src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #trg_mask = [batch size, trg len]\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "            \n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        \n",
    "        #encoder attention Q is coming from Decoder while K and V are coming from encoder\n",
    "        # the src_mask is to stop the decoder from using the <PAD> values in case if any\n",
    "        #enc_src=[batchsize,source_len,hid_dim]\n",
    "        #src_mask=[batbatch_size,source_len]\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        \n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "                    \n",
    "        _trg=self.positionwise_feedforward(trg)\n",
    "        \n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        \n",
    "        return trg,attention\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this module will encapsulate the encoder -decoder piece . it will also take care of the maskings\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder, \n",
    "                 decoder, \n",
    "                 src_pad_idx, \n",
    "                 trg_pad_idx, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    #this is just to add the 0s at the places which are pad\n",
    "    def make_src_mask(self, src):        \n",
    "        #src = [batch size, src len] \n",
    "        ## we are chaecking if the word is not a <PAD>..\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        #first check for the padding and make them 0\n",
    "        ##this is also checking if the word is not a PAD\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        trg_len = trg.shape[1]\n",
    "\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "\n",
    "        #if the padding is giving some more locatiosn as 0 then include them as well\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        \n",
    "        return trg_mask\n",
    "         \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "    def forward(self,src,trg):\n",
    "            \n",
    "        #src_mask=[batch size,1,1,src len]\n",
    "        src_mask = self.make_src_mask(src)\n",
    "\n",
    "        #trg_mask=[batch size,1,1,trg len]\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "\n",
    "        #enc_src=[batch size, src len, hid dim]\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "\n",
    "        ##output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n_heads, trg len, src len]  ..in case of the encoder it is bs,nhead,src_len,src_len\n",
    "        ## but in the case of the decoder Q is coming from decoder(aka target) so trg_len and \n",
    "        ## K is coming from encoder so src_len\n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        return output,attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,652,303 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##weight initialization\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(initialize_weights);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## this is the code to make sure that all the sentences are propelry formed that is required for the trainign\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# # helper function to club together sequential operations\n",
    "# def sequential_transforms(*transforms):\n",
    "#     def func(txt_input):\n",
    "#         for transform in transforms:\n",
    "#             txt_input = transform(txt_input)\n",
    "#         return txt_input\n",
    "#     return func\n",
    "\n",
    "# # function to add BOS/EOS and create tensor for input sequence indices\n",
    "# def tensor_transform(token_ids: List[int]):\n",
    "#     return torch.cat((torch.tensor([BOS_IDX]), \n",
    "#                       torch.tensor(token_ids), \n",
    "#                       torch.tensor([EOS_IDX])))\n",
    "\n",
    "# # src and tgt language text transforms to convert raw strings into tensors indices\n",
    "# text_transform = {}\n",
    "# for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "#     text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "#                                                vocab_transform[ln], #Numericalization\n",
    "#                                                tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# # function to collate data samples into batch tesors\n",
    "# def collate_fn(batch):\n",
    "#     src_batch, tgt_batch = [], []\n",
    "#     for src_sample, tgt_sample in batch:\n",
    "#         src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "#         tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "#     src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "#     tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "#     return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# def train_epoch(model, optimizer):\n",
    "#     model.train()\n",
    "#     losses = 0\n",
    "# #     train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "# #     train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    \n",
    "#     #for src, tgt in train_dataloader:\n",
    "#     count=0\n",
    "#     for i,batch in enumerate(train_iterator):\n",
    "#         src = batch.SRC.to(device)\n",
    "#         tgt = batch.TRG.to(device)\n",
    "#         # print(src.shape)\n",
    "#         # print(tgt.shape)\n",
    "#         # print(tgt[:,:-1].shape)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         ##some issue here...need to check\n",
    "#         output, _ = model(src, tgt[:,:-1])\n",
    "\n",
    "#         output_dim = output.shape[-1]\n",
    "            \n",
    "#         output = output.contiguous().view(-1, output_dim)\n",
    "#         tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "#         # output = output[1:].view(-1, output.shape[-1])\n",
    "#         # tgt = tgt[1:].reshape(-1) #tgt[:,:-1][1:].reshape(-1)\n",
    "#         loss = loss_fn(output, tgt)\n",
    "#         loss.backward()\n",
    "#         clip = 1\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "#         optimizer.step()\n",
    "#         losses += loss.item()\n",
    "#         count+=1\n",
    "\n",
    "#     return losses / count\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "#     train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "#     train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    \n",
    "    #for src, tgt in train_dataloader:\n",
    "    count=0\n",
    "    for i,batch in enumerate(train_iterator):\n",
    "        try:\n",
    "            src = batch.SRC.to(device)\n",
    "            tgt = batch.TRG.to(device)\n",
    "            # print(src.shape)\n",
    "#             print(tgt.shape)\n",
    "#             print(tgt[:,:-1].shape)\n",
    "#             print(i)\n",
    "\n",
    "#             print(batch.SRC)\n",
    "#             print(batch.TRG)\n",
    "#             print(\"i=\",i)\n",
    "#             lst=batch.SRC.tolist()\n",
    "#             print(lst)\n",
    "#             for b in lst:\n",
    "#                 print(\"length of file\", len(b))\n",
    "#                 for j in b:\n",
    "#                     print(SRC.vocab.itos[j])\n",
    "#                 print(\"------\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(src, tgt[:,:-1]) #[:,:-1])\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "#             output = output.contiguous().view(-1, output_dim)\n",
    "#             tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "            # output = output[1:].view(-1, output.shape[-1])\n",
    "            # tgt = tgt[1:].reshape(-1) #tgt[:,:-1][1:].reshape(-1)\n",
    "            loss = loss_fn(output, tgt)\n",
    "            loss.backward()\n",
    "            clip = 1\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            losses += loss.item()\n",
    "            count+=1\n",
    "        except:\n",
    "            print(\"error found at \",i)\n",
    "                        # print(src.shape)\n",
    "#             print(tgt.shape)\n",
    "#             print(tgt[:,:-1].shape)\n",
    "#             print(i)\n",
    "\n",
    "#             print(batch.SRC)\n",
    "#             print(batch.TRG)\n",
    "#             print(\"i=\",i)\n",
    "#             lst=batch.SRC.tolist()\n",
    "#             print(lst)\n",
    "#             for b in lst:\n",
    "#                 print(\"length of file\", len(b))\n",
    "#                 for j in b:\n",
    "#                     print(SRC.vocab.itos[j])\n",
    "#                 print(\"------\")\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    return losses / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "#     val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "#     val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    count=0\n",
    "    for i,batch in enumerate(train_iterator):\n",
    "        src = batch.SRC.to(device)\n",
    "        tgt = batch.TRG.to(device)[:,:-1]\n",
    "        \n",
    "        output, _ = model(src, tgt[:,:-1])\n",
    "        \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "        # output = output[1:].view(-1, output.shape[-1])\n",
    "        # tgt = tgt[1:].reshape(-1)\n",
    "        loss = loss_fn(output, tgt)\n",
    "        losses += loss.item()\n",
    "        count+=1\n",
    "    return losses / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error found at  0\n",
      "error found at  1\n",
      "error found at  2\n",
      "error found at  3\n",
      "error found at  4\n",
      "error found at  5\n",
      "error found at  6\n",
      "error found at  7\n",
      "error found at  8\n",
      "error found at  9\n",
      "error found at  10\n",
      "error found at  11\n",
      "error found at  12\n",
      "error found at  13\n",
      "error found at  14\n",
      "error found at  15\n",
      "error found at  16\n",
      "error found at  17\n",
      "error found at  18\n",
      "error found at  19\n",
      "error found at  20\n",
      "error found at  21\n",
      "error found at  22\n",
      "error found at  23\n",
      "error found at  24\n",
      "error found at  25\n",
      "error found at  26\n",
      "error found at  27\n",
      "error found at  28\n",
      "error found at  29\n",
      "error found at  30\n",
      "error found at  31\n",
      "error found at  32\n",
      "error found at  33\n",
      "error found at  34\n",
      "error found at  35\n",
      "error found at  36\n",
      "error found at  37\n",
      "error found at  38\n",
      "error found at  39\n",
      "error found at  40\n",
      "error found at  41\n",
      "error found at  42\n",
      "error found at  43\n",
      "error found at  44\n",
      "error found at  45\n",
      "error found at  46\n",
      "error found at  47\n",
      "error found at  48\n",
      "error found at  49\n",
      "error found at  50\n",
      "error found at  51\n",
      "error found at  52\n",
      "error found at  53\n",
      "error found at  54\n",
      "error found at  55\n",
      "error found at  56\n",
      "error found at  57\n",
      "error found at  58\n",
      "error found at  59\n",
      "error found at  60\n",
      "error found at  61\n",
      "error found at  62\n",
      "error found at  63\n",
      "error found at  64\n",
      "error found at  65\n",
      "error found at  66\n",
      "error found at  67\n",
      "error found at  68\n",
      "error found at  69\n",
      "error found at  70\n",
      "error found at  71\n",
      "error found at  72\n",
      "error found at  73\n",
      "error found at  74\n",
      "error found at  75\n",
      "error found at  76\n",
      "error found at  77\n",
      "error found at  78\n",
      "error found at  79\n",
      "error found at  80\n",
      "error found at  81\n",
      "error found at  82\n",
      "error found at  83\n",
      "error found at  84\n",
      "error found at  85\n",
      "error found at  86\n",
      "error found at  87\n",
      "error found at  88\n",
      "error found at  89\n",
      "error found at  90\n",
      "error found at  91\n",
      "error found at  92\n",
      "error found at  93\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3ad274655f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#val_loss = evaluate(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-431e001c7e47>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, optimizer)\n",
    "    end_time = timer()\n",
    "    #val_loss = evaluate(model)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Train PPL: {math.exp(train_loss):7.3f}  \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    train_losses.append(train_loss)\n",
    "    #val_losses.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch: 1, Train loss: 4.027, Train PPL:  56.102 | Val loss: 3.030, Val. PPL:  20.690 | Epoch time = 21.458s\n",
    "Epoch: 2, Train loss: 2.643, Train PPL:  14.049 | Val loss: 2.407, Val. PPL:  11.095 | Epoch time = 21.550s\n",
    "Epoch: 3, Train loss: 2.072, Train PPL:   7.944 | Val loss: 2.182, Val. PPL:   8.864 | Epoch time = 21.634s\n",
    "Epoch: 4, Train loss: 1.703, Train PPL:   5.492 | Val loss: 2.080, Val. PPL:   8.002 | Epoch time = 21.682s\n",
    "Epoch: 5, Train loss: 1.435, Train PPL:   4.199 | Val loss: 2.045, Val. PPL:   7.730 | Epoch time = 21.998s\n",
    "Epoch: 6, Train loss: 1.225, Train PPL:   3.403 | Val loss: 2.045, Val. PPL:   7.727 | Epoch time = 22.008s\n",
    "Epoch: 7, Train loss: 1.049, Train PPL:   2.854 | Val loss: 2.051, Val. PPL:   7.777 | Epoch time = 22.021s\n",
    "Epoch: 8, Train loss: 0.905, Train PPL:   2.472 | Val loss: 2.121, Val. PPL:   8.342 | Epoch time = 21.982s\n",
    "Epoch: 9, Train loss: 0.792, Train PPL:   2.209 | Val loss: 2.179, Val. PPL:   8.834 | Epoch time = 22.050s\n",
    "Epoch: 10, Train loss: 0.700, Train PPL:   2.014 | Val loss: 2.217, Val. PPL:   9.178 | Epoch time = 22.096s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 100):\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "#     if isinstance(sentence, str):\n",
    "#         src_tensor = text_transform[SRC_LANGUAGE](sentence).unsqueeze(0).to(device)\n",
    "#     else:\n",
    "#         src_tensor = text_transform[TGT_LANGUAGE](sentence).unsqueeze(0).to(device)\n",
    "    \n",
    "#     src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    \n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    #trg_indexes = [trg_field[init_token]]\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        #if pred_token == trg_field[eos_token]:\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    #trg_tokens = [trg_field.vocab.get_itos()[i] for i in trg_indexes]\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src =  why are there css changes ? the ticket does nt mention anything\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  why is this removed ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  why are we processing only pending ocm entries ? you should be fetching the ocm mapping for the given guid and company ' ( from the event ' ) and : \n",
      "\n",
      "  if it exists , mark the status to whatever is incoming from the event . \n",
      "\n",
      " if not present in ocm & & event is assoc , then add an entry \n",
      "\n",
      " do you see any issue with the above approach ?\n",
      "trg = add logical_suggestion end\n",
      "predicted trg = add logical_suggestion end <eos>\n",
      "****************************************\n",
      "src =  why is ` 91 ` being handled separately ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  @{557058:4e711a49 - b8fe-4901 - 8633 - 13a0c17ad34c } then should it not be ` stringutils.isnotempty(dialcode ) ? dialcode :  91  ` ?\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  in disassoc - you will not be creating the record . you should be marking it inactive only if the record already exists .\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  no point in throwing this .. an error msg is good enough . there is no caller to this .\n",
      "trg = add logical_suggestion end\n",
      "predicted trg = add logical_suggestion end <eos>\n",
      "****************************************\n",
      "src =  is there any need to set globaloutletid here ? it seems this api is handling only the records where guid matched .\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  is the full stop required ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  what about the error ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  @{5ffc28ed208dbf0107da7ae3 } , one suggestion for infinite scroll . keep the loader component at the bottom of the page instead of the top\n",
      "trg = add logical_suggestion end\n",
      "predicted trg = add logical_suggestion end <eos>\n",
      "****************************************\n",
      "src =  ` blankslate ` takes children , which we can have the action button , \n",
      "\n",
      " ref . * * noconnection.jsx * * component\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  use ` < react . fragment > ` instead of ` < > `\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  this might block the user to go to other page . please check what happens when we have an error\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{5ffc28ed208dbf0107da7ae3 } it matters for readability . so , i want to make a standard .\n",
      "trg = add refactoring_suggestion end\n",
      "predicted trg = add refactoring_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{5ffc28ed208dbf0107da7ae3 } same here . use ` < react . fragment > ` instead of ` < > `\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  if there is a value from getsimilarhiddenprojection , then do we need a default ? \n",
      "\n",
      " also has nt flow shown an error , where you have an empty object , and are trying to get the alias part of something that s not there\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  is the space required ?\n",
      "trg = add refactoring_suggestion end\n",
      "predicted trg = add refactoring_suggestion end <eos>\n",
      "****************************************\n",
      "src =  to just add a vertical padding we have created a button , is it useful ? \n",
      "\n",
      " when we customise button component , it should be override the button default styles , not what should be around the button .\n",
      "trg = add logical_suggestion end\n",
      "predicted trg = add logical_suggestion end <eos>\n",
      "****************************************\n",
      "src =  cleanup please .\n",
      "trg = add refactoring_suggestion end\n",
      "predicted trg = add refactoring_suggestion end <eos>\n",
      "****************************************\n",
      "src =  what is the violation that s happening ? is this the list part of dashboard ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  kindly make the same changes here too .\n",
      "trg = add completeness_suggestion end\n",
      "predicted trg = add completeness_suggestion end <eos>\n",
      "****************************************\n",
      "src =  this is wrong . you are checking for the string type includes , and you are putting an array for default . \n",
      "\n",
      " please use the correct things\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  is this an array as well ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  this is the third ` useeffect ` in this file , going forward we may have stability issue here .\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  why is this extra check required ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  so if you have a newvalue , then you are not using it anywhere in the function ? why do you require this ?\n",
      "trg = add refactoring_suggestion end\n",
      "predicted trg = add refactoring_suggestion end <eos>\n",
      "****************************************\n",
      "src =  your variable name is in positive sense , but your check / condition is in the negative sense . please make it clear . \n",
      "\n",
      " use something like ` const isfieldandcomparisontypepresent = tempcomparisonmodel [ ] || tempcomparisonmodel [ ] ` , the brackets indicate the key inside .\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  why are we starting validation with true ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  please write the reverse way of this . code will be hard to read for people in future .\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  less than what ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  @{5f1ea4d770fb250022a6f5c1 } , pre - approving this pr on my end . looks like you have only string changes , once you confirm with the product . \n",
      "\n",
      " validations looks good as well\n",
      "trg = add completeness_suggestion end\n",
      "predicted trg = add completeness_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{557058 : aaf7087e-8a1d-4e36 - b39c - d97d58086db2 } sir , comparision model supported reports are breaking with the new changes .\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  why this space ?\n",
      "trg = add refactoring_suggestion end\n",
      "predicted trg = add refactoring_suggestion end <eos>\n",
      "****************************************\n",
      "src =  we will not hardcode like this !\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  what we are trying to do there ? not recommended assigning ` window.location.href ` directly .\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  ` color=\"black \" ` ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  we will not do this !\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  * we will not hardcode and make input styled input for one place . \n",
      " * color hardcoded here . \n",
      " * spacing hardcoded here \n",
      "\n",
      " \n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  nope ! we will not do like this !\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  nope ! we will hardcode color like these !\n",
      "trg = add buggycode_suggestion end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  inline styles ! we will not do this !\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  this is not a component ! it s a utils helper i believe .\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  why is refetchquery required like this ? i thought the main idea was to remove the dashboard from the cache . \n",
      "\n",
      " please explain , if i m missing something\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  where exactly is the classes being used here ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  why the span is required ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  do we need the space after dashboards or reports ?\n",
      "trg = add questioning end\n",
      "predicted trg = add refactoring_suggestion end <eos>\n",
      "****************************************\n",
      "src =  please do nt use inline styling\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  why is this required ?\n",
      "trg = add questioning end\n",
      "predicted trg = add questioning end <eos>\n",
      "****************************************\n",
      "src =  @{557058 : aaf7087e-8a1d-4e36 - b39c - d97d58086db2 } use theme object to get white color , it must be there already .\n",
      "trg = add reuse_suggestion end\n",
      "predicted trg = add reuse_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{557058 : aaf7087e-8a1d-4e36 - b39c - d97d58086db2 } using history of ` react - router - dom ` . you can checkout other places in the code base .\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{557058 : aaf7087e-8a1d-4e36 - b39c - d97d58086db2 } that s not the way , texts should be always inside typography . check other places how we have done .\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{557058 : aaf7087e-8a1d-4e36 - b39c - d97d58086db2 } use available color palette in theme object .\n",
      "trg = add reuse_suggestion end\n",
      "predicted trg = add reuse_suggestion end <eos>\n",
      "****************************************\n",
      "src =  can we remove the console , if not required ?\n",
      "trg = add refactoring_suggestion end\n",
      "predicted trg = add refactoring_suggestion end <eos>\n",
      "****************************************\n",
      "src =  why is the variable address1 ?\n",
      "trg = add spelling_suggestion end\n",
      "predicted trg = add spelling_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{557058 : b9557086 - 1e7e-44c9 - 9383 - 1c4bb5904f76 } , pr looks good . i do nt have access to the ticket , that s why i ca nt check the contract . @{5d4aae425b8ea70c7e4f400a } , maybe some light can be shed here . \n",
      "\n",
      " approving the pr\n",
      "trg = add encouragement end\n",
      "predicted trg = add logistics_suggestion end <eos>\n",
      "****************************************\n",
      "src =  we have discussed to make similar structure . why we are not doing this ? \n",
      "\n",
      " otherwise we are writing if - else in every function .\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{5f1ea4d770fb250022a6f5c1 }   \n",
      "  \n",
      " every - time action we are converting structure from * * linked list = > array * * and * * vice - versa * * . so we are using * * tree for doing operation * * and * * array for displaying * * component purpose . \n",
      "\n",
      " if i understand it correctly , we are trying to use linkedlist structure to optimise iterations and performance . as per above execution , are we really achieving our goal ? is it not costing us more ?\n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add buggycode_suggestion end <eos>\n",
      "****************************************\n",
      "src =  instead of two operations , if we update the current node value with ` default_join ` , would that not solve our problem . \n",
      "\n",
      " or if we can have a ` replace ( ) ` function ?\n",
      "trg = add code_suggestion end\n",
      "predicted trg = add code_suggestion end <eos>\n",
      "****************************************\n",
      "src =  * check function naming please \n",
      " * instead of specific validation function , please have one common validation function \n",
      "\n",
      " \n",
      "trg = add buggycode_suggestion end\n",
      "predicted trg = add completeness_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{5f1ea4d770fb250022a6f5c1 } did you check this comment ?\n",
      "trg = add completeness_suggestion end\n",
      "predicted trg = add completeness_suggestion end <eos>\n",
      "****************************************\n",
      "src =  @{5f1ea4d770fb250022a6f5c1 }    \n",
      "  \n",
      " i am not convinced with the approach we took here . as we are projecting we have solved this using  * * doubly  linkedlist * *  approach to  * * optimise complexity * * . but here what we are doing more iteration than simple  * * array * *  implementation . also we are switching between  * * linkedlist < = > array * *  in every single action . \n",
      "\n",
      " now we are playing with less number of items ' ( i.e. joins ' ) now we are not observing much difference here . even if we play with 50 joins ' ( that 's a huge number i believe for this case ' ) we wo n't observe much of a difference there . so , please discuss and take opinion from @{5ba9f12799f8c8584576cbe3 } @{557058:4e711a49 - b8fe-4901 - 8633 - 13a0c17ad34c } @{557058 : aaf7087e-8a1d-4e36 - b39c - d97d58086db2 } & others  as well and proceed . \n",
      "\n",
      " _ * * note : please make sure there is no other change except re - arrange in this pr * * _\n",
      "trg = add buggycode_suggestion end\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5514/4205901274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trg =\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predicted trg =\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/1328497713.py\u001b[0m in \u001b[0;36mtranslate_sentence\u001b[0;34m(sentence, src_field, trg_field, model, device, max_len)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0menc_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#trg_indexes = [trg_field[init_token]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformerlatest/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/3171198587.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m##this is how the batch will look like after combining the scaling factor, positional embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformerlatest/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformerlatest/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformerlatest/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "for example_idx in range(1200,1300):\n",
    "\n",
    "    src = vars(test_data.examples[example_idx])['SRC']\n",
    "    trg = vars(test_data.examples[example_idx])['TRG']\n",
    "\n",
    "    print(\"src = \",' '.join(src))\n",
    "    print(\"trg =\" ,' '.join(trg))\n",
    "\n",
    "    translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "    print(\"predicted trg =\" ,' '.join(translation))\n",
    "    print(\"*\"*40)\n",
    "    #print(f'predicted trg = {' '.join(translation)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
    "    \n",
    "    assert n_rows * n_cols == n_heads\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,25))\n",
    "    \n",
    "    for i in range(n_heads):\n",
    "        \n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        \n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "        cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                           rotation=45)\n",
    "        ax.set_yticklabels(['']+translation)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_idx in range(8,12):\n",
    "\n",
    "    src = vars(train_data.examples[example_idx])['SRC']\n",
    "    trg = vars(train_data.examples[example_idx])['TRG']\n",
    "\n",
    "    print(\"src = \",' '.join(src))\n",
    "    print(\"trg =\" ,' '.join(trg))\n",
    "\n",
    "    translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "    print(\"predicted trg =\" ,' '.join(translation))\n",
    "    print(\"*\"*40)\n",
    "    #print(f'predicted trg = {' '.join(translation)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = Multi30k(split='test', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "c = 0\n",
    "\n",
    "print(\"*\"*40)\n",
    "print(\"German to English Translations:-\")\n",
    "print(\"*\"*40)\n",
    "for src, trg in list(data_iter):\n",
    "  print('\\n')\n",
    "  print(f\"{c+1}) Germal Sentence: {src}\")\n",
    "  print(f\"Target English Sentence: {trg}\")\n",
    "  \n",
    "  pred, attention = translate_sentence(src, vocab_transform[SRC_LANGUAGE], vocab_transform[TGT_LANGUAGE], model, device, '<bos>', '<eos>')\n",
    "\n",
    "  print(f\"Predicted English Sentence: {' '.join(pred[:-1])}\")\n",
    "  # print(\"Attention Map: \")\n",
    "  # display_attention(src, pred, attention)\n",
    "\n",
    "  c += 1\n",
    "  if c >= 10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_indexes = [vocab_transform['de']['<bos>']]\n",
    "trg_indexes\n",
    "trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "trg_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough just checking some concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src=torch.randn(2,6,20)\n",
    "#src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to('cuda')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##src is a tensor with [batch_size, number of tokens in a batch, embedding size ]\n",
    "batch_size=src.shape[0]\n",
    "src_len=src.shape[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what ever is the bacth size we want to create that many number of batches of the length =src_len \n",
    "pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to('cuda')\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_q=nn.Linear(20,20)\n",
    "Q=fc_q(src)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = Q.view(2, -1, 4, 5).permute(0,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = Q.view(2, -1, 4, 5).permute(0,2,1,3)\n",
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K1=Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(Q1,K1.permute(0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tril(torch.ones((10,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=K=torch.randn(1,2,6,10)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr=torch.matmul(Q,K.permute(0,1,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.permute(0,1,3,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "train_dataloader = DataLoader(train_iter, batch_size=1,collate_fn=collate_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for src,tgt in train_dataloader:\n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    count+=1\n",
    "    if count>10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "\n",
    "train_dataloader1 = DataLoader(train_iter, batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src,trg in list(train_iter):\n",
    "    sentence=src\n",
    "    print(sentence)\n",
    "    #if isinstance(sentence, str):\n",
    "    src_tensor = text_transform[SRC_LANGUAGE](sentence).unsqueeze(0).to(device)\n",
    "#     #else:\n",
    "#         src_tensor = text_transform[TGT_LANGUAGE](sentence).unsqueeze(0).to(device)\n",
    "   \n",
    "    print(src_tensor)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[   2,   22,   86,  258,   32,   88,   23,   95,    8,   17,  113, 7911,\n",
    "         3210,    5,    3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders\n",
    "\n",
    "there are two ways to access the data which is in the pairs of german and english\n",
    "1. using the normal iterator.\n",
    "2. create a data loader and then use it.\n",
    "The only difference is that when we use the data loader we dont have to perform the extra transformation step which we will have to other wise perform for the iterator\n",
    "\n",
    "The following are equivalent\n",
    "```\n",
    "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "//without the collate_fn and batch=1 the dataloader is same as the iterator\n",
    "train_dataloader1 = DataLoader(train_iter, batch_size=1,collate_fn=collate_fn)\n",
    "\n",
    "for src,tgt in train_dataloader:\n",
    "    print(src)\n",
    "    print(tgt)\n",
    "   \n",
    "```\n",
    "\n",
    "this can be written as \n",
    "```\n",
    "for src,tgt in list(train_iter):\n",
    "    ## this is plain german\n",
    "    print(src)\n",
    "    ##this is plain english\n",
    "    print(tgt)\n",
    "    \n",
    "    ## we have to apply the text_transform which is \n",
    "    ##sequential_transforms(token_transform[ln], #Tokenization\n",
    "    ##                                           vocab_transform[ln], #Numericalization\n",
    "    ##                                           tensor_transform)\n",
    "    src_tensor = text_transform[SRC_LANGUAGE](src).unsqueeze(0).to(device)\n",
    "    \n",
    "    \n",
    " ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = Multi30k(split='test', language_pair=('de','en'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ger-eng-test.csv\", mode='w') as fp:\n",
    "    fp.write('\"{}\",\"{}\"\\n'.format(\"SRC\",\"TRG\"))\n",
    "    for src, trg in list(data_iter):\n",
    "        print(src,trg)\n",
    "        fp.write('\"{}\",\"{}\"\\n'.format(src.strip(),trg.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>prId</th>\n",
       "      <th>commentText</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>253171795</td>\n",
       "      <td>10696</td>\n",
       "      <td>Ill check today and merge if every thing fine.</td>\n",
       "      <td>Arvind Kandi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253276755</td>\n",
       "      <td>10703</td>\n",
       "      <td>Please add space after the comma to follow the...</td>\n",
       "      <td>Narasimha Kamath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253350022</td>\n",
       "      <td>10704</td>\n",
       "      <td>In this why fetching orderdetails. This will c...</td>\n",
       "      <td>Arvind Kandi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253350069</td>\n",
       "      <td>10704</td>\n",
       "      <td>same here.</td>\n",
       "      <td>Arvind Kandi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253521772</td>\n",
       "      <td>10704</td>\n",
       "      <td>How can list give multiple fields?</td>\n",
       "      <td>Laxmikanth T D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>263411080</td>\n",
       "      <td>11209</td>\n",
       "      <td>Ignore this. We are inserting entry in DC for ...</td>\n",
       "      <td>Narasimha Kamath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>263752488</td>\n",
       "      <td>11212</td>\n",
       "      <td>fulfilment is not done by retailer, can we use...</td>\n",
       "      <td>Laxmikanth T D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>263752815</td>\n",
       "      <td>11212</td>\n",
       "      <td>As this is used during order fulfil and order ...</td>\n",
       "      <td>Laxmikanth T D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>263766222</td>\n",
       "      <td>11212</td>\n",
       "      <td>Can we read this setting outside?</td>\n",
       "      <td>Dharshan Kumar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>263769019</td>\n",
       "      <td>11212</td>\n",
       "      <td>Here the data is  being taken from a variable ...</td>\n",
       "      <td>Laxmikanth T D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     commentId   prId                                        commentText  \\\n",
       "0    253171795  10696    Ill check today and merge if every thing fine.   \n",
       "1    253276755  10703  Please add space after the comma to follow the...   \n",
       "2    253350022  10704  In this why fetching orderdetails. This will c...   \n",
       "3    253350069  10704                                         same here.   \n",
       "4    253521772  10704                 How can list give multiple fields?   \n",
       "..         ...    ...                                                ...   \n",
       "399  263411080  11209  Ignore this. We are inserting entry in DC for ...   \n",
       "400  263752488  11212  fulfilment is not done by retailer, can we use...   \n",
       "401  263752815  11212  As this is used during order fulfil and order ...   \n",
       "402  263766222  11212                  Can we read this setting outside?   \n",
       "403  263769019  11212  Here the data is  being taken from a variable ...   \n",
       "\n",
       "               author  \n",
       "0        Arvind Kandi  \n",
       "1    Narasimha Kamath  \n",
       "2        Arvind Kandi  \n",
       "3        Arvind Kandi  \n",
       "4      Laxmikanth T D  \n",
       "..                ...  \n",
       "399  Narasimha Kamath  \n",
       "400    Laxmikanth T D  \n",
       "401    Laxmikanth T D  \n",
       "402    Dharshan Kumar  \n",
       "403    Laxmikanth T D  \n",
       "\n",
       "[404 rows x 4 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
